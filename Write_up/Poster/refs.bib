@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  publisher={GitHub},
  howpublished={\url{https://github.com/fchollet/keras}},
}

@article{VebjornLjosa2012Ahmi,
issn = {1548-7091},
journal = {Nature Methods},
volume = {9},
publisher = {Nature Publishing Group},
number = {7},
year = {2012},
title = {Annotated high-throughput microscopy image sets for validation},
author = {Vebjorn Ljosa and Katherine L Sokolnicki and Anne E Carpenter},
}

@MISC{Plummer03jags,
    author = {Martyn Plummer},
    title = {JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling},
    year = {2003}
}
@article{FalkThorsten2019Udlf,
issn = {1548-7091},
journal = {Nature Methods},
volume = {16},
publisher = {Nature Publishing Group},
number = {1},
year = {2019},
title = {U-Net: deep learning for cell counting, detection, and morphometry},
language = {eng},
author = {Falk, Thorsten and Mai, Dominic and Bensch, Robert and Cicek, Ozgun and Abdulkadir, Ahmed and Marrakchi, Yassine and Bohm, Anton},
keywords = {Computer Science ; Machine Learning ; Image Processing},
}
@article{VehtariAki2017PBme,
issn = {0960-3174},
abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
journal = {Statistics and Computing},
pages = {1413--1432},
volume = {27},
publisher = {Springer US},
number = {5},
year = {2017},
title = {Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC},
language = {eng},
address = {New York},
author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
keywords = {Bayesian computation ; Leave-one-out cross-validation (LOO) ; -fold cross-validation ; Widely applicable information criterion (WAIC) ; Stan ; Pareto smoothed importance sampling (PSIS)},
}
